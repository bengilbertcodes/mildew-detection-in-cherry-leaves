{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer Business Requirement 2:\n",
        "    * The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* /workspace/mildew-detection-in-cherry-leaves/inputs/cherry-leaves/train\n",
        "* /workspace/mildew-detection-in-cherry-leaves/inputs/cherry-leaves/validation\n",
        "* /workspace/mildew-detection-in-cherry-leaves/inputs/cherry-leaves/test\n",
        "* image shape embeddings.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Images distribution plot in train, validation and test sets.\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels.\n",
        "* Machine learning model creation and training.\n",
        "* Save model.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "* Prediction on a random image file.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "cwd = os.getcwd()\n",
        "cwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(cwd))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "working_dir = os.getcwd()\n",
        "working_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set input directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set train, validation and test paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherry-leaves'\n",
        "train_path = os.path.join(my_data_dir, 'train')\n",
        "val_path = os.path.join(my_data_dir, 'validation')\n",
        "test_path = os.path.join(my_data_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v5'\n",
        "file_path = os.path.join('outputs', version)\n",
        "\n",
        "if 'outputs' in os.listdir(working_dir) and version in os.listdir(os.path.join(working_dir, 'outputs')):\n",
        "    print('Old version is already available. Create a new version')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Labels for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "version = 'v5'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Images Distribution in Train, Validation and Test datasets\n",
        "\n",
        "### Image Distribution Bar Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([])\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        df_freq = df_freq.append(\n",
        "            pd.Series(data={'Set': folder,\n",
        "                            'Label': label,\n",
        "                            'Frequency': int(len(os.listdir(os.path.join(my_data_dir, folder, label))))}\n",
        "                      ),\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {len(os.listdir(os.path.join(my_data_dir, folder, label)))} images\")\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title('Cherry Leaves Dataset Label Distribution')\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Distribution Pie Figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folders = os.listdir(my_data_dir)\n",
        "data = []\n",
        "\n",
        "# Iterating through folders and labels\n",
        "for folder in folders:\n",
        "    n = 0  # Initialize count\n",
        "    for label in labels:\n",
        "        # Get the number of files in each subdirectory\n",
        "        n += len(os.listdir(os.path.join(my_data_dir, folder, label)))\n",
        "    data.append(n)\n",
        "\n",
        "# Plotting the pie chart\n",
        "px = 1 / plt.rcParams['figure.dpi']\n",
        "plt.subplots(figsize=(800 * px, 250 * px))\n",
        "colors = sns.color_palette('deep')[1:6]\n",
        "plt.pie(data, labels=folders, colors=colors, autopct='%.0f%%')\n",
        "plt.title('Cherry Leaves Dataset Distribution')\n",
        "plt.savefig(f'{file_path}/sets_distribution_pie.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Image Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Initialise ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 20 # set batch size\n",
        "\n",
        "train_data = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                      target_size=image_shape[:2],\n",
        "                                                      color_mode='rgb',\n",
        "                                                      batch_size=BATCH_SIZE,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      shuffle=True\n",
        "                                                      )\n",
        "\n",
        "train_data.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_data = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                         target_size=image_shape[:2],\n",
        "                                                                         color_mode='rgb',\n",
        "                                                                         batch_size=BATCH_SIZE,\n",
        "                                                                         class_mode='categorical',\n",
        "                                                                         shuffle=False\n",
        "                                                                         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                   target_size=image_shape[:2],\n",
        "                                                                   color_mode='rgb',\n",
        "                                                                   batch_size=BATCH_SIZE,\n",
        "                                                                   class_mode='categorical',\n",
        "                                                                   shuffle=False\n",
        "                                                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    img, label = train_data.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    img, label = validation_data.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    img, label = test_data.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_data.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Model Creation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML model\n",
        "\n",
        "* ### Import model packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Convolutional Block\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "                     input_shape=image_shape, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten and Dense Layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.6))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adagrad',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Early Stopping/Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-6)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# m_checkpoint = ModelCheckpoint(\n",
        "#     filepath='outputs/v4/mildew_detection_model_{epoch:02d}_{val_accuracy:.4f}.h5',  # Save with epoch and val_accuracy in the filename\n",
        "#     monitor='val_accuracy',  # Monitor validation accuracy\n",
        "#     mode='max',  # Save when accuracy improves\n",
        "#     save_best_only=True,  # Only save the best model to avoid multiple files\n",
        "#     save_weights_only=False,  # Save the entire model (architecture + weights)\n",
        "#     verbose=1  # Verbosity to show when saving happens\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "history = model.fit(train_data,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_data.classes) // BATCH_SIZE,\n",
        "          validation_data=validation_data,\n",
        "          callbacks=[early_stop, reduce_lr],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v5/mildew_detection_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance\n",
        "\n",
        "---\n",
        "\n",
        "### Model Learning Curve - A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_accuracy.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve - B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(model.history.history).plot(figsize=(8, 5))\n",
        "\n",
        "plt.savefig(f'{file_path}/model_loss_accuracy.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve - C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['val_loss'], name=\"val_loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['loss'], name=\"loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['val_accuracy'], name=\"val accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['accuracy'], name=\"accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=\"Loss/Accuracy of LSTM Model\"\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "fig.update_yaxes(title_text=\"<b>primary</b> Loss\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"<b>secondary</b> Accuracy\", secondary_y=True)\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=800, \n",
        "    height=500, \n",
        "    )\n",
        "\n",
        "fig.show()\n",
        "fig.write_image(f'{file_path}/model_history.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('outputs/v5/mildew_detection_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy\n",
        "Aims:\n",
        "* Evaluation of the model on the test set.\n",
        "* Confirm that the performance on the test set meets the requirements of at least 65% accuracy and answers Business Requirement 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_data, batch_size=BATCH_SIZE)\n",
        "print(\"Model Accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
        "print(\"Model Loss: \", evaluation[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set accuracy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_data.reset()\n",
        "\n",
        "x_true, y_true = next(test_data)\n",
        "preds = np.argmax(model.predict(test_data), axis=1)\n",
        "y_pred = np.rint(preds)\n",
        "y_true = test_data.labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8, 5))\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, label=\"Random Classifier\", linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(f'{file_path}/roccurve.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "print('Area Under ROC-Curve: ', roc_auc_score(y_true, y_pred))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "classes=list(test_data.class_indices.keys()) \n",
        "length=len(classes)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "plt.xticks(np.arange(length)+.5, classes, rotation= 0, fontsize=8)\n",
        "plt.yticks(np.arange(length)+.3, classes, rotation=90, fontsize=8)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report - A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Classification Report A:\\n----------------------\\n')\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report - B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "clf_report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, cmap=\"Blues\", cbar=False, linewidths=1)\n",
        "plt.title('Classification Report B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report - C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "\n",
        "def plot_classification_report(y_true, y_pred, title='Classification Report', save_fig_path=None, **kwargs):\n",
        "    # Create classification report dictionary\n",
        "    clf_report = classification_report(y_true, y_pred, output_dict=True, **kwargs)\n",
        "\n",
        "    # Filter out 'accuracy', 'macro avg', and 'weighted avg'\n",
        "    keys_to_plot = [key for key in clf_report.keys() if key not in ('accuracy', 'macro avg', 'weighted avg')]\n",
        "    df = pd.DataFrame(clf_report, columns=keys_to_plot).T\n",
        "    \n",
        "    # Sort by 'support' column\n",
        "    df.sort_values(by=['support'], inplace=True)\n",
        "\n",
        "    # Create a mask for the support column to handle it separately\n",
        "    rows, cols = df.shape\n",
        "    mask = np.zeros((rows, cols))\n",
        "    mask[:, cols-1] = True  # Mask out the 'support' column for the first heatmap\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    # Plot the heatmap without 'support'\n",
        "    ax = sns.heatmap(df.iloc[:, :-1], mask=mask[:, :-1], annot=True, cmap='plasma', fmt='.3g', cbar=False,\n",
        "                     vmin=0.0, vmax=1.0, linewidths=.4, linecolor='white')\n",
        "\n",
        "    # Mask for 'support' column (second heatmap)\n",
        "    mask_support = np.zeros((rows, cols))\n",
        "    mask_support[:, :-1] = True  # Mask everything except 'support'\n",
        "\n",
        "    # Plot support column as a second heatmap with separate formatting\n",
        "    ax = sns.heatmap(df.iloc[:, -1:], mask=mask_support[:, -1:], annot=True, cmap='YlGn', fmt=',.0f', cbar=False,\n",
        "                     linewidths=2, linecolor='white', \n",
        "                     vmin=df['support'].min(), vmax=df['support'].sum(),\n",
        "                     norm=mpl.colors.Normalize(vmin=df['support'].min(), vmax=df['support'].sum())\n",
        "                    )\n",
        "    \n",
        "    # Set the title and axis labels\n",
        "    plt.title(title)\n",
        "    plt.yticks(np.arange(len(df)) + 0.5, df.index, rotation=0)  # Fix the y-tick labels\n",
        "\n",
        "    # Save the figure if a path is provided\n",
        "    if save_fig_path:\n",
        "        path = pathlib.Path(save_fig_path)\n",
        "        path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(save_fig_path)\n",
        "    \n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "fig, ax = plot_classification_report(y_true, y_pred, \n",
        "                                     title='Classification Report',\n",
        "                                     target_names=labels,\n",
        "                                     save_fig_path=f'{file_path}/clf_report.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Evaluation Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v5/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Random Image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming test_path, labels, and image_shape are defined earlier in the code\n",
        "pointer = 44  # Choose a specific image index\n",
        "label = labels[0]  # '1' corresponds to 'powdery mildew', '0' would be for 'healthy'\n",
        "\n",
        "# Load the image using Keras' image processing utilities\n",
        "img_path = os.path.join(test_path, label, os.listdir(os.path.join(test_path, label))[pointer])\n",
        "pil_image = image.load_img(img_path, target_size=image_shape, color_mode='rgb')\n",
        "\n",
        "# Print image details\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(pil_image)\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert Image to Array for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict Class Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_data.class_indices.items()}\n",
        "pred_class = target_map[pred_proba < 0.5]\n",
        "\n",
        "if pred_class == target_map[1]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
